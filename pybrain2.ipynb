{
 "metadata": {
  "name": "",
  "signature": "sha256:ddad4761326dbf283b376b019fed5084b77c6a50cd3b69f5d84d378681dfe731"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pybrain\n",
      "reload(pybrain)\n",
      "import json\n",
      "import pandas as pd\n",
      "import json\n",
      "from collections import defaultdict\n",
      "import numpy as np\n",
      "\n",
      "import pybrain.datasets\n",
      "reload(pybrain.datasets)\n",
      "import pybrain.supervised.trainers\n",
      "from pybrain.structure.connections import FullConnection\n",
      "from pybrain.structure.connections import CustomFullConnection\n",
      "from pybrain.utilities import percentError\n",
      "from pybrain.tools import validation\n",
      "reload(validation)\n",
      "# from validation import CrossValidator\n",
      "# from pybrain.structure.connections import IdentityConnection\n",
      "# from pybrain.structure.connections.connection import Connection\n",
      "\n",
      "# pathways = json.load(open('pathways/kegg_api_dict.txt'))\n",
      "# data = pd.DataFrame.from_csv('/users/ryan/softwareprojects/r/scaled_ GSE4588 .txt')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<module 'pybrain.tools.validation' from '/Users/Ryan/anaconda/lib/python2.7/site-packages/PyBrain-0.3.3-py2.7.egg/pybrain/tools/validation.pyc'>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "def get_pathway_dict(pathway_file, data):\n",
      "    new_kegg=[]\n",
      "    api_pathways=defaultdict(list)\n",
      "\n",
      "    with open(pathway_file) as f:\n",
      "        for line in f:\n",
      "            ids=line.strip().split('\\t')\n",
      "            if ids[1][4:] in data.index.values.tolist():\n",
      "                api_pathways[ids[0]].append(ids[1][4:])\n",
      "    print len(api_pathways)\n",
      "    api_pathways2=api_pathways.copy()\n",
      "    for key in api_pathways:\n",
      "        if not api_pathways[key]:\n",
      "            del api_pathways2[key]\n",
      "    print len(api_pathways2)\n",
      "    return dict(api_pathways2)\n",
      "\n",
      "#     outfile=open('kegg_api_dict.txt','wb')\n",
      "#     json.dump(api_pathways,outfile,indent=1,sort_keys=True)\n",
      "    \n",
      "\n",
      "def sync_data_pathways(data,pathways):\n",
      "    #reduces genes in dataframe to only genes in pathways\n",
      "    genes_in_paths=[]\n",
      "    for path in pathways:\n",
      "        genes_in_paths+=pathways[path]\n",
      "    genes_to_keep=list(set(genes_in_paths))\n",
      "    \n",
      "    data1=data.loc[genes_to_keep]\n",
      "    return data1\n",
      "\n",
      "\n",
      "\n",
      "# pathways = get_pathway_dict('pathways/kegg_api.txt',data)\n",
      "# print pathways\n",
      "# data = sync_data_pathways(data,pathways)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def add_pathway_connections(network, first_layer, second_layer, data, pathways):\n",
      "    #now the tricky layer from the pathways database  \n",
      "    \n",
      "    entrez_dict = {} #entrez dict connects entrezids to the index of the feature vector\n",
      "    for i,entrez in enumerate(data.index.values.tolist()):\n",
      "        entrez_dict[entrez] = i\n",
      "\n",
      "    \n",
      "    for path_index, path in enumerate(pathways.keys()):\n",
      "        g_index=[]\n",
      "        for g in pathways[path]:\n",
      "            g_index.append(entrez_dict[g])\n",
      "        network.addConnection(CustomFullConnection(first_layer,second_layer,\\\n",
      "                                        inSliceIndices=g_index,  \\\n",
      "                                        outSliceIndices=[path_index]))\n",
      "    return network\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## build structure\n",
      "def build_flat_network(data, pathways, layers=2):\n",
      "    #data is a data frame straight from affy - columns are patients, rows are entrez genes\n",
      "    #pathways is a dict with {pathway1:[gene1, gene2, ...], pathway2:[gene, gene...]...}\n",
      "\n",
      "    in_data = data.values.T\n",
      "\n",
      "    fnn = pybrain.structure.networks.FeedForwardNetwork()\n",
      "\n",
      "    inLayer = pybrain.structure.LinearLayer(in_data.shape[1])\n",
      "    fnn.addInputModule(inLayer)\n",
      "\n",
      "    outLayer = pybrain.structure.SoftmaxLayer(2)\n",
      "    fnn.addOutputModule(outLayer)\n",
      "\n",
      "    hidden_list=[]\n",
      "    #right now I have two sigmoid hidden layers \n",
      "    #can and will probably change\n",
      "    for i in range(layers):\n",
      "        hidden_list.append(pybrain.structure.SigmoidLayer(len(pathways)))\n",
      "        fnn.addModule(hidden_list[i])\n",
      "    \n",
      "    \n",
      "    \n",
      "    ## add connections input to hidden is sparse, but second hidden and output are fully connected\n",
      "    \n",
      "    #add fully connected layers\n",
      "    hidden_to_out = pybrain.structure.connections.FullConnection(hidden_list[-1],outLayer)\n",
      "    fnn.addConnection(hidden_to_out)\n",
      "\n",
      "    \n",
      "#     hidden_connects=[]\n",
      "    for hl in range(1,layers):\n",
      "        #this first step may be unncessary, but I am saving the connections objects to a list incase I need them later\n",
      "#         hidden_connects.append(FullConnection(hidden_list[hl-1],hidden_list[hl]))\n",
      "        fnn.addConnection(FullConnection(hidden_list[hl-1],hidden_list[hl]))\n",
      "\n",
      "    #now the tricky layer from the pathways database\n",
      "#     fnn = add_pathway_connections(fnn, inLayer, hidden_list[0], data, pathways)\n",
      "\n",
      "    #temp\n",
      "    fnn.addConnection(pybrain.structure.connections.FullConnection(inLayer,hidden_list[0]))\n",
      "\n",
      "\n",
      "    fnn.sortModules()\n",
      "    return fnn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def build_deep_network(data, pathways, filters=5, third_layer_nodes=5):\n",
      "    #data is a data frame straight from affy - columns are patients, rows are entrez genes\n",
      "    #pathways is a dict with {pathway1:[gene1, gene2, ...], pathway2:[gene, gene...]...}\n",
      "    \n",
      "    layers = filters\n",
      "    \n",
      "    in_data = data.values.T\n",
      "\n",
      "    fnn = pybrain.structure.networks.FeedForwardNetwork()\n",
      "\n",
      "    inLayer = pybrain.structure.LinearLayer(in_data.shape[1])\n",
      "    fnn.addInputModule(inLayer)\n",
      "\n",
      "    outLayer = pybrain.structure.SoftmaxLayer(2)\n",
      "    fnn.addOutputModule(outLayer)\n",
      "\n",
      "    hidden_list=[]\n",
      "    #right now I have two sigmoid hidden layers \n",
      "    #can and will probably change\n",
      "    for i in range(layers):\n",
      "        hidden_list.append(pybrain.structure.SigmoidLayer(len(pathways)))\n",
      "        fnn.addModule(hidden_list[i])\n",
      "    \n",
      "    clean_up_layer = pybrain.structure.SigmoidLayer(third_layer_nodes)\n",
      "    fnn.addModule(clean_up_layer)\n",
      "    \n",
      "    \n",
      "    \n",
      "    ## add connections input to hidden is sparse, but second hidden and output are fully connected\n",
      "    \n",
      "    #add fully connected layers\n",
      "    hidden_to_out = pybrain.structure.connections.FullConnection(clean_up_layer,outLayer)\n",
      "    fnn.addConnection(hidden_to_out)\n",
      "\n",
      "    \n",
      "#     hidden_connects=[]\n",
      "    for hl in hidden_list:\n",
      "        #this first step may be unncessary, but I am saving the connections objects to a list incase I need them later\n",
      "#         hidden_connects.append(FullConnection(hidden_list[hl-1],hidden_list[hl]))\n",
      "        fnn.addConnection(FullConnection(h1,clean_up_layer))\n",
      "\n",
      "        #now the tricky layer from the pathways database\n",
      "        fnn = add_pathway_connections(fnn, inLayer, h1, data, pathways)\n",
      "\n",
      "\n",
      "    fnn.sortModules()\n",
      "    return fnn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test code on small set of rituximab samples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load in raw data\n",
      "tnfa_raw = pd.DataFrame.from_csv('/users/ryan/softwareprojects/R/tnfa_response_expression.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set up y vector (1 is responder, 0 is non-responder)\n",
      "# classes = []\n",
      "# for i in range(18):\n",
      "#     classes.append(1)\n",
      "    \n",
      "# for i in range(18,42):\n",
      "#     classes.append(0)\n",
      "\n",
      "# for i in range(42, 49):\n",
      "#     classes.append(0)\n",
      "    \n",
      "# for i in range(49,len(tnfa_raw.columns.values.tolist())):\n",
      "#     classes.append(1)\n",
      "classes=[]\n",
      "for i in range(100):\n",
      "    classes.append(0)\n",
      "for i in range(100,299):\n",
      "    classes.append(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pathways = get_pathway_dict('pathways/kegg_api.txt',tnfa_raw)\n",
      "data = sync_data_pathways(tnfa_raw,pathways)\n",
      "fnn=build_flat_network(data, pathways)\n",
      "# print fnn.connections"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "295\n",
        "295\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convertDataNeuralNetwork(x, y):\n",
      "    colx = 1 if len(np.shape(x))==1 else np.size(x, axis=1)\n",
      "    coly = 1 if len(np.shape(y))==1 else np.size(y, axis=1)\n",
      "    \n",
      "    fulldata = pybrain.datasets.ClassificationDataSet(colx,coly, nb_classes=2)\n",
      "    for d, v in zip(x, y):\n",
      "        fulldata.addSample(d, v)\n",
      "    \n",
      "    return fulldata\n",
      "\n",
      "\n",
      "maxEpochs = 5000\n",
      "epochsperstep = 100\n",
      "learningrate = 0.01\n",
      "lrdecay = 1.0\n",
      "momentum = 0.\n",
      "\n",
      "\n",
      "x=data.values.T\n",
      "y=np.array(classes)\n",
      "\n",
      "\n",
      "fulldata = convertDataNeuralNetwork(x, y)\n",
      "# fulldata._convertToOneOfMany()\n",
      "# print fulldata\n",
      "\n",
      "Train, Test = fulldata.splitWithProportion(.75)\n",
      "Train._convertToOneOfMany()\n",
      "Test._convertToOneOfMany()\n",
      "\n",
      "\n",
      "trainer =  pybrain.supervised.trainers.BackpropTrainer(fnn, dataset=Train, verbose=False, \\\n",
      "                                                       learningrate = learningrate, lrdecay = lrdecay, momentum = momentum)\n",
      "\n",
      "\n",
      "# print validation.CrossValidator(trainer, fulldata, n_folds=3,max_epochs=1).validate()\n",
      "# print fnn(x[1,:])\n",
      "# trainer.trainEpochs( 1 )\n",
      "# trainer.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# trainer.trainEpochs( 10 )\n",
      "print fnn.activate(x[1,:])\n",
      "print fnn.activate(x[2,:])\n",
      "print fnn.activate(x[3,:])\n",
      "print fnn.activate(x[4,:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  9.99999969e-01   3.13083660e-08]\n",
        "[  9.99999997e-01   3.08251558e-09]\n",
        "[  9.99999999e-01   1.43072880e-09]\n",
        "[  1.00000000e+00   5.09201490e-11]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(10):\n",
      "    trainer.trainEpochs( 1 )\n",
      "    trnresult = percentError( trainer.testOnClassData(),\n",
      "                              Train['class'] )\n",
      "    tstresult = percentError( trainer.testOnClassData(\n",
      "           dataset=Test ), Test['class'] )\n",
      "\n",
      "    print \"epoch: %4d\" % trainer.totalepochs, \\\n",
      "          \"  train error: %5.2f%%\" % trnresult, \\\n",
      "          \"  test error: %5.2f%%\" % tstresult"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch:    1   train error: 32.14%   test error: 30.67%\n",
        "epoch:    2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 26.79%   test error: 28.00%\n",
        "epoch:    3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 29.02%   test error: 36.00%\n",
        "epoch:    4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 43.30%   test error: 56.00%\n",
        "epoch:    5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 30.36%   test error: 22.67%\n",
        "epoch:    6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 38.39%   test error: 54.67%\n",
        "epoch:    7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 34.38%   test error: 53.33%\n",
        "epoch:    8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 23.66%   test error: 46.67%\n",
        "epoch:    9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 24.11%   test error: 45.33%\n",
        "epoch:   10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error: 20.98%   test error: 26.67%\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for m in fnn.modules:\n",
      "#     print m\n",
      "#     print fnn.connections[m], '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets            import ClassificationDataSet\n",
      "from pybrain.utilities           import percentError\n",
      "from pybrain.tools.shortcuts     import buildNetwork\n",
      "from pybrain.supervised.trainers import BackpropTrainer\n",
      "from pybrain.structure.modules   import SoftmaxLayer\n",
      "\n",
      "# from pylab import ion, ioff, figure, draw, contourf, clf, show, hold, plot\n",
      "from scipy import diag, arange, meshgrid, where\n",
      "from numpy.random import multivariate_normal\n",
      "\n",
      "\n",
      "means = [(-1,0),(2,4),(3,1)]\n",
      "cov = [diag([1,1]), diag([0.5,1.2]), diag([1.5,0.7])]\n",
      "alldata = ClassificationDataSet(2, 1, nb_classes=3)\n",
      "for n in xrange(400):\n",
      "    for klass in range(3):\n",
      "        input = multivariate_normal(means[klass],cov[klass])\n",
      "        alldata.addSample(input, [klass])\n",
      "        \n",
      "        \n",
      "tstdata, trndata = alldata.splitWithProportion( 0.25 )\n",
      "\n",
      "trndata._convertToOneOfMany( )\n",
      "tstdata._convertToOneOfMany( )\n",
      "\n",
      "print \"Number of training patterns: \", len(trndata)\n",
      "print \"Input and output dimensions: \", trndata.indim, trndata.outdim\n",
      "print \"First sample (input, target, class):\"\n",
      "print trndata['input'][0], trndata['target'][0], trndata['class'][0]\n",
      "\n",
      "\n",
      "fnn = buildNetwork( trndata.indim, 5, trndata.outdim, outclass=SoftmaxLayer )\n",
      "\n",
      "trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)\n",
      "\n",
      "ticks = arange(-3.,6.,0.2)\n",
      "X, Y = meshgrid(ticks, ticks)\n",
      "# need column vectors in dataset, not arrays\n",
      "griddata = ClassificationDataSet(2,1, nb_classes=3)\n",
      "for i in xrange(X.size):\n",
      "    griddata.addSample([X.ravel()[i],Y.ravel()[i]], [0])\n",
      "griddata._convertToOneOfMany()  # this is still needed to make the fnn feel comfy\n",
      "\n",
      "\n",
      "for i in range(5):\n",
      "    trainer.trainEpochs( 1 )\n",
      "    trnresult = percentError( trainer.testOnClassData(),\n",
      "                              trndata['class'] )\n",
      "    tstresult = percentError( trainer.testOnClassData(\n",
      "           dataset=tstdata ), tstdata['class'] )\n",
      "\n",
      "    print \"epoch: %4d\" % trainer.totalepochs, \\\n",
      "          \"  train error: %5.2f%%\" % trnresult, \\\n",
      "          \"  test error: %5.2f%%\" % tstresult\n",
      "            \n",
      "    out = fnn.activateOnDataset(griddata)\n",
      "    print 'first out',out\n",
      "    out = out.argmax(axis=1)  # the highest output activation gives the class\n",
      "    print 'second out',out\n",
      "    out = out.reshape(X.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of training patterns:  900\n",
        "Input and output dimensions:  2 3\n",
        "First sample (input, target, class):\n",
        "[ 3.79219649 -0.1020359 ] [0 0 1] [2]\n",
        "Total error:  0.0604778084386"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch:    1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.89%   test error:  4.00%\n",
        "first out"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [[ 0.87506827  0.07707057  0.04786117]\n",
        " [ 0.87367169  0.07512877  0.05119955]\n",
        " [ 0.87214168  0.07338895  0.05446937]\n",
        " ..., \n",
        " [ 0.09287193  0.57616978  0.33095829]\n",
        " [ 0.09177967  0.55788162  0.35033871]\n",
        " [ 0.09044358  0.53775455  0.37180187]]\n",
        "second out [0 0 0 ..., 1 1 1]\n",
        "Total error:  0.0329553891795"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch:    2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.11%   test error:  4.33%\n",
        "first out"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [[ 0.92730783  0.03410441  0.03858776]\n",
        " [ 0.92561364  0.03292275  0.04146361]\n",
        " [ 0.92390101  0.03190897  0.04419002]\n",
        " ..., \n",
        " [ 0.08197495  0.69508134  0.22294371]\n",
        " [ 0.08214926  0.68037269  0.23747805]\n",
        " [ 0.08222624  0.66290265  0.25487111]]\n",
        "second out [0 0 0 ..., 1 1 1]\n",
        "Total error:  0.0266186584224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch:    3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  6.44%   test error:  5.67%\n",
        "first out"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [[ 0.93502779  0.02488998  0.04008223]\n",
        " [ 0.93261249  0.0236669   0.04372061]\n",
        " [ 0.93018259  0.02264446  0.04717294]\n",
        " ..., \n",
        " [ 0.0502699   0.70585767  0.24387243]\n",
        " [ 0.05059286  0.68283932  0.26656782]\n",
        " [ 0.05078892  0.65513655  0.29407452]]\n",
        "second out [0 0 0 ..., 1 1 1]\n",
        "Total error:  0.0235532606306"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch:    4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  5.89%   test error:  5.33%\n",
        "first out"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [[ 0.94562349  0.01764672  0.03672979]\n",
        " [ 0.94298995  0.01666996  0.04034008]\n",
        " [ 0.94037394  0.0158673   0.04375877]\n",
        " ..., \n",
        " [ 0.04595964  0.73899315  0.21504721]\n",
        " [ 0.04657686  0.71433462  0.23908852]\n",
        " [ 0.04709452  0.68407285  0.26883263]]\n",
        "second out [0 0 0 ..., 1 1 1]\n",
        "Total error:  0.0218757782649"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch:    5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  5.67%   test error:  4.67%\n",
        "first out"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [[ 0.94794237  0.01346674  0.03859089]\n",
        " [ 0.94529827  0.01276572  0.04193601]\n",
        " [ 0.94275753  0.01219633  0.04504615]\n",
        " ..., \n",
        " [ 0.03902822  0.79972944  0.16124234]\n",
        " [ 0.0397617   0.78359494  0.17664336]\n",
        " [ 0.04055444  0.76321289  0.19623266]]\n",
        "second out [0 0 0 ..., 1 1 1]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}